{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The file has 887085 characters, 77 of which are unique.\n"
     ]
    }
   ],
   "source": [
    "#import text file\n",
    "data = open(\"emma.txt\", 'r').read()\n",
    "\n",
    "def char_info(data):\n",
    "    unique = set()\n",
    "    num = []\n",
    "    for line in data:\n",
    "        for char in line:\n",
    "            unique.add(char)\n",
    "            num.append(char)\n",
    "    return list(unique), num\n",
    "            \n",
    "unique_chars, non_unique = char_info(data)\n",
    "\n",
    "\n",
    "print(\"The file has %d characters, %d of which are unique.\" % (len(non_unique), len(unique_chars)))\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert Characters to Integers so that they may be fed into and RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "char_to_idx = {ch : i for i, ch in enumerate(unique_chars)}\n",
    "idx_to_char = {i:ch for i, ch in enumerate(unique_chars)}\n",
    "#print(char_to_ix)\n",
    "#print(ix_to_char)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "#create a vector from a character\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "vector_for_char_a = np.zeros((len(unique_chars), 1))\n",
    "vector_for_char_a[char_to_idx['a']] = 1\n",
    "print(vector_for_char_a.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hyperparameters for network\n",
    "\n",
    "hidden_size = 100 #number of neurons in hidden layer\n",
    "seq_length = 25 #number of characters generated at every time step\n",
    "learning_rate = 1e-1 #how quickly a network abandons old beliefs for new ones\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model parameters\n",
    "import random\n",
    "wxh = np.random.randn(hidden_size, len(unique_chars))*0.01 #weights from input to hidden state\n",
    "whh = np.random.randn(hidden_size, hidden_size)*0.01#recurrent weight matrix\n",
    "why = np.random.randn(len(unique_chars), hidden_size) * 0.01\n",
    "bh = np.zeros((hidden_size, 1))#bias for hidden state\n",
    "by = np.zeros((len(unique_chars),1))#bias for output layer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Defining the Loss Function!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lossfun(inputs, targets, hprev):\n",
    "    \"\"\"\n",
    "    inputs, targets are lists of integers\n",
    "    hprev is an Hx1 array of the initial hidden state\n",
    "    the function will return the loss, gradients on model paremtnets and the last hidden state\n",
    "    \"\"\"\n",
    "    #store our inputs, hiddenstates, outputs and probs as dicts\n",
    "    xs, hs, ys, ps = {}, {}, {}, {}\n",
    "    #each will be seq_length long\n",
    "    #xs will store 1 enodend input char for each of the 25 time steps\n",
    "    #hs will store hidden state outputs for 25 time steps\n",
    "    #how to calculate the hidden state at t =0\n",
    "    #ys will store targets\n",
    "    #ps will take the ys and convert to normalized probs for chars\n",
    "    #could use list but need an entry of -1 to calc the 0th hidden layer\n",
    "    # -1 as a list idx would wrap around to the final element\n",
    "    \n",
    "    \n",
    "    #we do not want hs[-1] to automatically change if hprev is changed\n",
    "    hs[-1] = np.copy(hprev)\n",
    "    #set initial loss as 0\n",
    "    loss = 0\n",
    "    \n",
    "    #code the forward pass\n",
    "    \n",
    "    for t in range(len(inputs)):\n",
    "        xs[t] = np.zeros((len(unique_chars), 1)) # place a 0 vector as the t-th input\n",
    "        xs[t][inputs[t]] = 1 #inside the t-th input we use the integer in the inputs list to set the correct value\n",
    "        hs[t] = np.tanh(np.dot(wxh, xs[t]) + np.dot(whh, hs[t-1]) + bh) # hidden state\n",
    "        \n",
    "        ys[t] = np.dot(why, hs[t]) + by # unnormalized log probs for next chars\n",
    "        ps[t] = np.exp(ys[t]) / np.sum(np.exp(ys[t])) # probs of next chars\n",
    "        loss += -np.log(ps[t][targets[t],0]) # softmax (cross_entropy loss)\n",
    "        \n",
    "    #backward pass: compute gradients going backwards\n",
    "    #initialize vectors for gradient values for each set of weights\n",
    "    dwxh, dwhh, dwhy = np.zeros_like(wxh), np.zeros_like(whh), np.zeros_like(why)\n",
    "    dbh, dby = np.zeros_like(bh), np.zeros_like(by)\n",
    "    dhnext = np.zeros_like(hs[0])\n",
    "    for t in reversed(range(len(inputs))):\n",
    "        #output probs\n",
    "        dy = np.copy(ps[t])\n",
    "        #derive our first gradient\n",
    "        dy[targets[t]] -= 1 # backprop into y\n",
    "        #compute output grad - output time hidden states transpose\n",
    "        #When we apply the transpose weight matrix,  \n",
    "        #we can think intuitively of this as moving the error backward\n",
    "        #through the network, giving us some sort of measure of the error \n",
    "        #at the output of the lth layer. \n",
    "        #output gradient\n",
    "        dwhy += np.dot(dy, hs[t].T)\n",
    "        #derivative of output bias\n",
    "        dby += dy\n",
    "        #backpropagate!\n",
    "        dh = np.dot(why.T, dy) + dhnext # backprop into h\n",
    "        \n",
    "        dhraw = (1-hs[t]*hs[t])*dh # backprop through tan nonlinearity\n",
    "        \n",
    "        dbh += dhraw #derivative of hidden bias\n",
    "        dwxh += np.dot(dhraw, xs[t].T) #derivative of input to hidden layer weight\n",
    "        dwhh += np.dot(dhraw, hs[t-1].T) # derivative of hidden layer to hidden layer weight\n",
    "        dhnext = np.dot(whh.T, dhraw)\n",
    "    for dparam in [dwxh, dwhh, dwhy, dbh, dby]:\n",
    "        np.clip(dparam, -5, 5, out=dparam) # clip to mitigate exploding gradients\n",
    "    \n",
    "    return loss, dwxh, dwhh, dwhy, dbh, dby, hs[len(inputs)-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a sentence from the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----\n",
      " E[XX]Bj43pJ!qAsRaVRHJbApf!'q-D6N:h_Y'_-cMAXn,Q]-eW4Swc SaXJ7DjW&eXe!!0F,CSh4(&unSX(ah,28pD2,WJMw_PlrsO.i;zIzAErpKeUy't:_Dofk07\n",
      "DdRC;zvA3s]X[[0hb0X\"fiY:NT\n",
      "msMV)U8lmfknyL,\"FaIxVdMxpP?kG)YPE6j.OY[VyEjO,f \n",
      "----\n"
     ]
    }
   ],
   "source": [
    "# prediction created from one full forward pass\n",
    "\n",
    "def sample(h, seed_idx, n):\n",
    "    \"\"\"\n",
    "    sample: a sequence of integers from the model\n",
    "    h = memory state\n",
    "    seed_idx = seed letter for first time step\n",
    "    n = how many characters to predict\n",
    "    \"\"\"\n",
    "    \n",
    "    #create input vect\n",
    "    x = np.zeros((len(unique_chars), 1))\n",
    "    #customise for our seed char\n",
    "    x[seed_idx] = 1\n",
    "    #list to store generated chars\n",
    "    idxs = []\n",
    "    #iterate through as many characters as we wish to generate\n",
    "    for t in range(n):\n",
    "        #hidden state at a given time step is a function\n",
    "        #of the input at the same time step modified by a weight matrix \n",
    "        #added to the hidden state of the previous time step \n",
    "        #multiplied by its own hidden state to hidden state matrix.\n",
    "        h = np.tanh(np.dot(wxh, x) + np.dot(whh, h) + bh)\n",
    "        #compute unormalised output\n",
    "        y = np.dot(why,h) + by\n",
    "        # prob for next chars\n",
    "        p = np.exp(y) / np.sum(np.exp(y))\n",
    "        #pick one with the highest prob\n",
    "        idx = np.random.choice(range(len(unique_chars)), p=p.ravel())\n",
    "        #create a vector\n",
    "        x = np.zeros((len(unique_chars), 1))\n",
    "        #customise for predicted char\n",
    "        x[idx] = 1\n",
    "        #add to the list\n",
    "        idxs.append(idx)\n",
    "        \n",
    "    txt = \"\".join(idx_to_char[idx] for idx in idxs)\n",
    "    print(\"----\\n %s \\n----\" % (txt, ))\n",
    "\n",
    "hprev = np.zeros((hidden_size,1)) # reset RNN mem\n",
    "#predict 200 characters give \"a\"\n",
    "sample(hprev, char_to_idx['a'], 200)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inputs [0, 49, 49, 27, 42, 39, 23, 23, 3, 2, 23, 58, 50, 24, 48, 42, 2, 27, 38, 3, 50, 23, 49, 24, 48]\n",
      "targets [49, 49, 27, 42, 39, 23, 23, 3, 2, 23, 58, 50, 24, 48, 42, 2, 27, 38, 3, 50, 23, 49, 24, 48, 42]\n"
     ]
    }
   ],
   "source": [
    "p=0\n",
    "\n",
    "inputs = [char_to_idx[ch] for ch in non_unique[p:p+seq_length]]\n",
    "print(\"inputs\", inputs)\n",
    "targets = [char_to_idx[ch] for ch in non_unique[p+1:p+seq_length+1]]\n",
    "print(\"targets\", targets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration 0, loss: 108.595123\n",
      "----\n",
      " \"xJ1;uSh3K8vMrVlNSCaKj0bR'FY3EMusIheJ:dU\"(Gud4IeO?DI?vEK17)cOU&KoYTlu8SMVRXv?6R]Fv&0E;xNOz _BT\"hTQysXa.A0J!\"CIpwDKwa011.'RO3M V;Dh7]Olyq&4ae)BeH1r7;jLASh\"ta8oNFTv2()Mxw:6Wh;TY;iSS]\n",
      "L!hRfhd.3E[E(]8mOvT \n",
      "----\n",
      "iteration 1000, loss: 87.207135\n",
      "----\n",
      " ut, rod Wouttos eoul\n",
      "\n",
      "hor Med hg dherir at hiet wour where hevr-\n",
      "W pheood har an.avo in nong ba refr he lheerll ted ham the walf\n",
      "har pw borsmhi rel.sreve\n",
      "hh peufepl\n",
      "\n",
      "Sharg\n",
      "d mhf fhirgeeler, ent ar oni \n",
      "----\n",
      "iteration 2000, loss: 71.551663\n",
      "----\n",
      " aisidoulfwas Mrivee harypisiserceveer botedsever thirhy sue, iuatheriooe pTenfsa. woukgaly wakly there chasfon wooking of thel., e fotertepnant yithe oonegmarfangau_tylcepthe onte touge aaiatithen hae \n",
      "----\n",
      "iteration 3000, loss: 64.120772\n",
      "----\n",
      " klaverpor.-aver bet bt wis therr\n",
      "Efuns fut pt her ifour sedd yphers for asd os wulgty an wrer, hdr onveres hee haver werr. war wrr; f che hen  ffry she ann is enuldshe Shert the ycr and at a atd pirci \n",
      "----\n",
      "iteration 4000, loss: 59.690535\n",
      "----\n",
      " non paghigode ow; pere.\n",
      "\n",
      "\"\"math y pchilpeve pir hep,\n",
      "wout.,\n",
      "\"She have  yom ag haveroone  hifghy vever\n",
      "comly to\n",
      "arvell mofelr inv\n",
      "\n",
      "Wtipl ancet\n",
      " At apuh she nogr nrece; ghren ,\n",
      "harmergo.\n",
      "\n",
      "\"\"\n",
      "\"\"\"\"\n",
      "\"\"\"\"\"\" \n",
      "----\n",
      "iteration 5000, loss: 56.941423\n",
      "----\n",
      " nkas touchidenrides her.\n",
      "Emmarto.\"\n",
      "\n",
      "\"The dothity comad,\n",
      "ras incelit mourly doaldel\n",
      "EHarmengech uf pwow aring.\" and ould jucd erte mmirerto andy ofteaem buesullingidien hace hest out oommany foce mo -w \n",
      "----\n",
      "iteration 6000, loss: 55.593527\n",
      "----\n",
      " -I sild\n",
      "uhysiny.\"\"um sinstit) I to so tourvend I klayge thithosed nossige itel, nos Elyon.--doussoulden wilbe onou noteas wishs and thinr rooghy\n",
      "ary to comoraen\n",
      "bediigsiss -and medt of of eur as ay ad \n",
      "----\n",
      "iteration 7000, loss: 54.341829\n",
      "----\n",
      " ertey a dire le kius heat, seess forict wen to no lerint an oRre atrer pearare wnabe, hy she nued nut Mr.\n",
      "\n",
      "\"Rhas than---\"and saa, nopads dit herer sI cofter me erur;; quts-so herend\n",
      "wirh for ef as ild \n",
      "----\n",
      "iteration 8000, loss: 53.571179\n",
      "----\n",
      " soussting sItord at at wace offsek\n",
      "a dosscaantieg heased thanghed but atut failedfor,\n",
      "of buh wialss ather hith moncorot ow thald as anwise, c the folling wat nowatasest of en aHe wenoucd\n",
      "miof star and \n",
      "----\n",
      "iteration 9000, loss: 52.763105\n",
      "----\n",
      " joll and ines sulfinn  they furunca, reune.\n",
      "Eptorer,\n",
      "at, I pienu heroust ondsingupn; wr. Wesain, mo dusinu.t\n",
      "ouss wo noant\n",
      "bour the stich hay to hy\n",
      "up, me wlen, her versstorrerp and. \n",
      "\"Your in yoocht  \n",
      "----\n",
      "iteration 10000, loss: 51.963557\n",
      "----\n",
      " ;\n",
      "dn\n",
      "oftter\n",
      "intleire wasmens, and to Knof ablebelougnounds tops. \n",
      "Then and outhebne.--Giffidaigisiot bey hay follase;\n",
      "wispile. But pomented deat to no the asailly abredsing of exto is y Deviow atloonf \n",
      "----\n",
      "iteration 11000, loss: 51.338963\n",
      "----\n",
      " agind pom asy kithuiow,\n",
      "\"The vist ly alding to nas shesaily ha, hein fow youning;-? when, wiosiElt sumadit, to oI wemandent himsingcady with wit her hes thery; and I ther to thacwise Jachiven, of ther \n",
      "----\n",
      "iteration 12000, loss: 51.507379\n",
      "----\n",
      "  be cisu and as timle cobl pase thed abre tha tu cofhlw.\n",
      "\n",
      "\n",
      "Churo cann\n",
      "in uuly the ar the dike a matirad the cone as, has dean\n",
      " I reen tping so han toly her in cane would a preer non me acan heim _feg  \n",
      "----\n",
      "iteration 13000, loss: 51.194510\n",
      "----\n",
      " we veherd tirtang wavlone her the and abmughing she mabeing she beslranger and oan shemperasy aflagaied the decey\n",
      "see have the and it in somstis; anw; a licplesy hanting to do lire hersly he moceratir \n",
      "----\n",
      "iteration 14000, loss: 51.103780\n",
      "----\n",
      " , by of lixely. You deen cime, hichith the\n",
      "the pimet, accus, gould tougs tocgePunk so dish qursaflrire.\"\n",
      "\n",
      "\"Lroncele you abef,\n",
      "fore co his to the mintsed\n",
      "anluim wast knok olly yuilious, by dont neg at  \n",
      "----\n",
      "iteration 15000, loss: 50.464118\n",
      "----\n",
      " , ham of inon wirl, windejbling to yed harpely;\n",
      "\n",
      "\n",
      "They of aint ow u\n",
      "muilibl;\n",
      "oned will his hert Mid hele ollore oon you, whor mate, immatit, and her.  Ther. Wesmous, and Tour.\n",
      "\n",
      "\"Wey agay.\n",
      "\n",
      "Hamd wother \n",
      "----\n",
      "iteration 16000, loss: 50.120056\n",
      "----\n",
      " ernoxy, the last it I leangh I beffyise Fure (forlion wher very.\"--Ther he farcering he hersings of cimly, abned,\n",
      "\n",
      "She mmste all tore\n",
      "we!menting sithight wam I fess yo given.  She coull and onh, Mr. - \n",
      "----\n",
      "iteration 17000, loss: 49.761750\n",
      "----\n",
      " ne gat ond jure asrily sein not sur--I gen' calt hill cofe it is surried.\n",
      "C\n",
      "Mr. Jhit thigily cive, in you so to be she Mas, Oixly helt shimcce, ublinfoul yous.--and that ReMriny of the ming.\" I a His  \n",
      "----\n",
      "iteration 18000, loss: 49.606123\n",
      "----\n",
      "  astrome monf lining that sino, Entun to depleet be, ancorry haed,\n",
      "ald very was Were, ashoullroon.\n",
      "\"\"aseing Cexteat you she dise incare, and of tas it harg--futpey not aphers, he nesual, she daity hav \n",
      "----\n",
      "iteration 19000, loss: 49.594878\n",
      "----\n",
      " eneyer\n",
      "and inytien\n",
      "sest or trigher axare to _ was meren engarn.  Frar, Fam As cpualingoug_ ensent _\"ane cenkery; invery theaned tief her, _ireingion oneatiteptily, mesels mume inmen,\n",
      "ang perfiel anour \n",
      "----\n",
      "iteration 20000, loss: 49.625758\n",
      "----\n",
      " mert yon taly betede quate'.  Epmachele of a very betbe ma.  no mibt to prownt for sting ty mand hims tolltiire thigt.--I do to blowdy the sound, no wisf olt, wow betict, card har om trife spever Mrsm \n",
      "----\n",
      "iteration 21000, loss: 49.294161\n",
      "----\n",
      " imed of exad being-wiow whemmedsorout her matte heysunding shis cake notseld onriripe,\n",
      "tehs sode for samatinenting suchow and the worricingsted and all\n",
      "of awax were to by\n",
      "olly the extmo no sucheded\n",
      "we \n",
      "----\n",
      "iteration 22000, loss: 49.161428\n",
      "----\n",
      " s,rodston was hid so in Inceent; inmaxded wrobest butenther evering to hathangher in retly mpan whill tee not not ist_s and orsely, Fr\n",
      "wing wis.\n",
      "pre-merl\n",
      "a wroth?-uake srestlisse ppow waland her su_tl \n",
      "----\n",
      "iteration 23000, loss: 48.577803\n",
      "----\n",
      " _,\n",
      "to Hert.\"\n",
      "\n",
      "Ento notce theare a oft to thate\n",
      "snot Rinct go sall, very fat befat avion\n",
      "that hakron have nech'ss.\n",
      "The the ue lisirest argar to  implestempongich.  I the tagidss mest oull.  I Theting a \n",
      "----\n",
      "iteration 24000, loss: 48.464673\n",
      "----\n",
      "  hers, Emma havey his if lily fulm lide abluve,\n",
      "would tele eving lost not liwt cowh alfod, bate befined by tay forcelce them exsiseabsul.--\n",
      "\"You getles cis.\n",
      "That much you. Wolainf.  Che tha plable thi \n",
      "----\n",
      "iteration 25000, loss: 48.547375\n",
      "----\n",
      " ormt indy wis I had thot of mushity.  EmRan agather her.\n",
      "And ye-s, Itseined ham seet\n",
      "betting reslive beatite dider sorry sther yous--\n",
      "Misine, young, was prain abes.  I muppons such beer,--should for y \n",
      "----\n",
      "iteration 26000, loss: 48.450843\n",
      "----\n",
      " an--depiry cime indos and High extlo fing,--Hiply th!--wny ultanging afrever; nolly wistbed--fod--veble--bule had otcare confontrast tnomed--but thide dond id will forable corce tugy dornbll--woubn--\n",
      " \n",
      "----\n",
      "iteration 27000, loss: 48.521825\n",
      "----\n",
      " ary foct!\"\n",
      "(indiss noull, be minceinten wall mease! nur,re exefvelg usty ammidsed)d.  The es, We me? sall,\n",
      "stlur shay oud ale dead frip shem.  And onkion ppeshing Mos ley dict to promle; pisteas Mr. I \n",
      "----\n",
      "iteration 28000, loss: 48.041083\n",
      "----\n",
      "  Mns and muct\n",
      "inule me oull Janing doushod exideld; it or.\"\n",
      "\n",
      "\n",
      "hand his ghing.  ne her, oble foulcse, Ghy ot mankt dyel inters han as pimet gom, ut the the with you, thenkenknor you ford's in oR dectan \n",
      "----\n",
      "iteration 29000, loss: 47.736753\n",
      "----\n",
      " pay a trice wong.!--\n",
      "\"He the lour hip,\"\n",
      "s that londing.\"\n",
      "\n",
      "And, that bncey and frous be loyt hippines,\"\n",
      "\n",
      "\n",
      "The sTit foony dy than be that fanpectance; of to face bot, pleacs not?\"--vist hersect of his n \n",
      "----\n",
      "iteration 30000, loss: 46.989114\n",
      "----\n",
      " un the sromed.  But hout elfoy, saad the sreal she demasurg daded taos tay her heur.\" wo desse, infth fectess opvatast expos rafancoure\n",
      "ghe ther frets she beledarffred wighor in mons.  That he whomed  \n",
      "----\n",
      "iteration 31000, loss: 46.746840\n",
      "----\n",
      " ecaigy come ad wer inin hispent and dowaeled\n",
      "as farn un Harrieved so batherst\n",
      "aidlant not,\n",
      "by a fise nover nops tinfce theve---\"Yow tonenarete, bayg\" not of a daidionbly to vady as seas, er engisuw th \n",
      "----\n",
      "iteration 32000, loss: 47.254229\n",
      "----\n",
      " g with you to hirce Rank and, then of hount foostapy you buchered, I as come sele notwened this at;--\n",
      "\n",
      "And oble the of thout itrlite the I swatiall, Fraghtent exeavent hy--Wood dixery _wast istored in \n",
      "----\n",
      "iteration 33000, loss: 47.250362\n",
      "----\n",
      " eallving and his notshingd befonce a was with re whell to a sonesten botire's beads.  Think much musion if anker;\n",
      "I hipr anst tonsingent happont.\n",
      "-And abentitithed jusser evtoacthy\n",
      "tunce.  He worricte \n",
      "----\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration 34000, loss: 47.295236\n",
      "----\n",
      " as spie sem youd have his abreced--\n",
      "\"An.\n",
      "\n",
      "\"Hen me she dake me to lester.--The wiss,\n",
      "my would we he cire.\"\n",
      "\n",
      "\"Uhim hapr her oxe, sery collible to doy wing hill at Emma,\n",
      "and us defubouw have ur ap is rea \n",
      "----\n",
      "iteration 35000, loss: 46.727740\n",
      "----\n",
      "   Hainh mupintsucistict, as leaintse\n",
      "conciresur, an for ompy\n",
      "such, exchindtingly you's mainufrepe\" do I wind.  I smed, Elec? \"Bu; ipcoush thuniet a my buwy he yom, Emma was you heargs. Eltonge, Emmaat \n",
      "----\n",
      "iteration 36000, loss: 47.128046\n",
      "----\n",
      " s ar of thy mist, beant to ameady.\n",
      "\"The shis wanf beevevirijlse, Misy had able,\n",
      "b\n",
      "the to strest besule.  It a vailed were.--uthat betan pros to be.\" I cothind food oltinill the she Hade.\"\n",
      "\"He that me, \n",
      "----\n",
      "iteration 37000, loss: 47.409678\n",
      "----\n",
      " s,\n",
      "a mayide evencs retery was bu.h umme,-- he for,\n",
      "spoolstang, leep two her,\n",
      "as.--\n",
      "Shable tas--wimmost Mar; be every taly my aaturltor o lamy props of by thins alyfwils gall meated wasmabtield vedy, o \n",
      "----\n",
      "iteration 38000, loss: 46.418841\n",
      "----\n",
      "  frouthelblavery, any hour herst.--Butey bully,\n",
      "why viry.  Thancwirine; wheren.  In spoker toctay.  Wooltiye _Ilry promelan lattuthtinin net plireat.  Wequits; was matedy.\n",
      "\"Nourtiond.\n",
      "She memer afnor  \n",
      "----\n",
      "iteration 39000, loss: 46.702783\n",
      "----\n",
      " ust wand yout wall parveat a bued rest?\"\n",
      "\n",
      "\"Yel, I saentes\n",
      "gostlogied conted wall Mry.  Tus reen my.\n",
      "Such a frelt\n",
      "be I be necce loirist the mufe he wiffy cy where not wound my; and ton nof arren sten M \n",
      "----\n",
      "iteration 40000, loss: 46.568006\n",
      "----\n",
      " er `Nuaun erstit, a cupest must of whill be; _say\n",
      "that.  The bo, to perser yot; ighnring you be but, be whole toduly can ofrove ditsed to plax,\n",
      "but sally is.\"\n",
      "\"\n",
      "Herser I smen grotled of, and, a the ma \n",
      "----\n",
      "iteration 41000, loss: 46.806488\n",
      "----\n",
      "   Harse, it minous supleare,--pod-wat not is quisacy ots to whandupunybreat coulsonte.  Mr.\n",
      "Sucsiif on soony blen har\n",
      "of she knad,\n",
      "I hid so her not plave the good lit is gear oppeckifating, pave it no \n",
      "----\n",
      "iteration 42000, loss: 46.818169\n",
      "----\n",
      " \n",
      "y the noth he suen not adles bo reall\n",
      "plost endeang subullly? I\n",
      "quile noacurnt to she heh lotteas for of his hays mean paited.\n",
      "Shely pere inew me, her befulg en would been! Sually in fill for so the  \n",
      "----\n",
      "iteration 43000, loss: 46.994190\n",
      "----\n",
      " xprace was a drotaly mome her you, abes, perd\n",
      "a me it, as seemade.  Let good shatams--and any araer.\n",
      "But not.\n",
      "Histne ware her fut.\n",
      "Yesing_\n",
      "do tall thighy not he my her so bent one not of the the pinen \n",
      "----\n",
      "iteration 44000, loss: 46.273050\n",
      "----\n",
      " shon was for very, to the will faint.t one perimar,\n",
      "ar fi_prre;\n",
      "\n",
      "Mr. Fre that it the amard me not shinkeabew it muppllasy Harhdated whither to bl wiss him \"ank Mr. Chuch thoule opse Mrs.\n",
      "\n",
      "The titt dit \n",
      "----\n",
      "iteration 45000, loss: 46.035854\n",
      "----\n",
      " matteres accuirist be oqure iter\n",
      "thew nothered to that reverd and so whem the at, fon, I minkonowtenh.  I stine.  He at her aid evers ald him riven to the socwririnveld ever. \"Why griout ald swind and \n",
      "----\n",
      "iteration 46000, loss: 45.721261\n",
      "----\n",
      " at do pould,\n",
      "and ronos agro, me buked in she resume of exliou pilitinifieit.  Sumprittabed ro,  impith and this to the buce deans much Emme thily urece\n",
      "anat of I cens would tool mest of thing\n",
      "fulg muc \n",
      "----\n",
      "iteration 47000, loss: 45.898610\n",
      "----\n",
      " e had him is have the ran, deaang congreal heme stom.  Anxer Jathelmenge a gimed even deal_ to Bould, in o whach am it intafce replinatiting\n",
      "to varling the devalbolt.  Butll\n",
      "the Dagrayfied thind besse \n",
      "----\n",
      "iteration 48000, loss: 46.188517\n",
      "----\n",
      " xcounlys to sook her you, came from.  You oven his inout aster was wild olranpsing a a fromtores's by's oor pert.  Thowes heyel,\n",
      "yoow, as not the sthe have tige.\n",
      "I so drace liken, a brare surtired, on \n",
      "----\n",
      "iteration 49000, loss: 46.340504\n",
      "----\n",
      " not the  Emsect\n",
      "fromed but is tonteds procery, deserary not of spokes When treoud, of follaly man.  Swa; as I tce so er would sus wasmendir no ther aod artedsed be a likester there\n",
      "and dortty\n",
      "ligt and \n",
      "----\n",
      "iteration 50000, loss: 46.405349\n",
      "----\n",
      " uls priture yousse--by she wangion, nothinbounged\n",
      "thel appriettel.--\"\n",
      "ithing?\"\n",
      "\n",
      "\"She is othen quith real's by meabys's\n",
      "whomer, crocty mushax oven somp, induselfint, for shise--fon moan meed leaming?-- \n",
      "----\n",
      "iteration 51000, loss: 45.705418\n",
      "----\n",
      " her pinqurrech be; and; nom had nothing maining tithing cale of now muct is hile hale\n",
      "thap with set Cowing a serither, that pardy soon were to be\n",
      "in concesing our, evanciblosl--thing grodiel rasure he \n",
      "----\n",
      "iteration 52000, loss: 45.514145\n",
      "----\n",
      " ting asht gomonivais hawcercerteunangasiels, goven uh Mr.  Aldre veaghebting Dong in ligher infod!\n",
      "In, with besure thought on whimenst, thiny to Mr. Knight plack\"s\"\n",
      "en sumpine as words werough--\n",
      "ould  \n",
      "----\n",
      "iteration 53000, loss: 45.987315\n",
      "----\n",
      "  chlidped sees been dood it.  Neen ?\" \"\"The hather she croming wquch mennkge I smany comper lon.  She marvervion I diling uncoke I mustod!--\"unit geshis-wonectice\n",
      "she modent bele.\n",
      "of Fairfle halk the  \n",
      "----\n",
      "iteration 54000, loss: 45.780343\n",
      "----\n",
      "  as urprean, fing, a shnong araved Mr--but be, it, mationgabtings.\n",
      "Cofone\n",
      "the ghim in not and.\n",
      "\n",
      "\"Theme anded fealionghtrong are of anrertedly, engided fouss--pted they spon objuged theyfed\n",
      "tuplrave wo \n",
      "----\n",
      "iteration 55000, loss: 45.425453\n",
      "----\n",
      " usty.\n",
      "\n",
      "There but he call was noim aige.  Wes nathese fattllismentatur Chank stly\n",
      "winl lige, for to not linct fend I was him-tan, so she which than it you destionsenty dide\" had theurnomed fon the deas \n",
      "----\n",
      "iteration 56000, loss: 46.024216\n",
      "----\n",
      " onded--to heiss goon's exarnended she\n",
      "propping, that Mims. \n",
      "Whad, Mr. Knight Jane a donion was quatidy Ha now; briny no dhan's-kisuon ale oulty Frakkuntsen she ton choughtled! and houhtater and us. Fu \n",
      "----\n",
      "iteration 57000, loss: 45.761319\n",
      "----\n",
      " \n",
      "oor as in.\n",
      "It hay.\"\n",
      "\n",
      "Emma it oth.\n",
      "\n",
      "It will tot plates of the in\n",
      "the aces, Ipony leadsinkning one boted not Mrs. Wescriet hiprorse.  I the eal smal Woul that mossure you knedading agat his tuelly tirn \n",
      "----\n",
      "iteration 58000, loss: 45.772150\n",
      "----\n",
      " elnt and iully the berare, anp\n",
      "I agroment.\"\n",
      "\n",
      "Emma a any drought ther to nookhou as she indonion you wotse pery pearalbufismers! Cowe they tolvioude than is mage has his so leswamed_, follondent free M \n",
      "----\n",
      "iteration 59000, loss: 45.320357\n",
      "----\n",
      " , _ithinly\n",
      "was nather, as being thought she fenss of the she what sere he ecalme?\"\n",
      "she perion fromune.\"\n",
      "\n",
      "\"What cowon by a manoet\n",
      "reree spirmance's but bucles--and prectlose finder. Emma.  Where have d \n",
      "----\n",
      "iteration 60000, loss: 51.207374\n",
      "----\n",
      " unlt  imad aman.  wand gem ixt it be touldo thyond hored ram awt rode ret nore jetnl. nena tom shestye  aur thir- thorhe wokes won. \"ave iler tcheds inegh as, 7es \n",
      "ang fooust we chex dond noouted tuin \n",
      "----\n",
      "iteration 61000, loss: 59.121946\n",
      "----\n",
      " .  Ite goun walpins Fien, fon bely wammow amfion, us quomint awd thma toor er  whill lis wesirted wint hees, her shaceith would ies Xynd wise in tessitelidfit, cog. wam (fout tash?h, _fhound. Jant lik \n",
      "----\n",
      "iteration 62000, loss: 58.066378\n",
      "----\n",
      "  wive jemen maye, ty to storind wald balsl troertas. Nontly comowm.\"\n",
      "\n",
      "Mrd tho mone she all it of thing las as drshang sumad in they soR satkh\n",
      " So cand nover  whon in slaccaite awot cocen mas,  ancurt  \n",
      "----\n",
      "iteration 63000, loss: 57.308299\n",
      "----\n",
      " le warce a rest Em thed anetles!--Weng burly cirsedt, of he feen,\n",
      "ovent yo.\n",
      "Youls--neg anewing ind af ure she os wor weet oouedt core havl-gt forves gy\n",
      "Mr.\n",
      "\n",
      "\"Mis areer, aghe sared to.\n",
      "You bot ar or.\n",
      "T \n",
      "----\n",
      "iteration 64000, loss: 55.569388\n",
      "----\n",
      " griid sty hasach redehe vimicy temely to toud neile, tam anr igourtery do; thite I pas erve, Fqusto. Brenire; info prrersey pe.\n",
      "\n",
      "\"Shigh;--buken hocy ex.  he nojarter ciore:--hage toore thanaind. Elten \n",
      "----\n",
      "iteration 65000, loss: 54.153031\n",
      "----\n",
      " bse a croom?\"\n",
      "Hare hat pott mard! fo he teldoce; sthan now le she tromebf at of fore inder tho incurnicuiring cot not fangedy she tle kot corret alns miverning hather, hint they\n",
      "goulyder no ot ware ho \n",
      "----\n",
      "iteration 66000, loss: 52.499897\n",
      "----\n",
      " Evint.  \"reechers hisiens yes, she wist golidelus eredresty ablighed\n",
      "wos,\n",
      "she is Mrthercerpenot\n",
      "aryng nos supfitcich, prring -I thy inise youtt.\n",
      "\n",
      "\n",
      "uDinr youly;\n",
      "\"I\n",
      "ste excet--\n",
      "REmmax's\n",
      "fitiry her pore  \n",
      "----\n",
      "iteration 67000, loss: 52.110935\n",
      "----\n",
      "  thathiffeng? Kneshself have--hant elne ankeng takankne, and lurpaurs; to lisin0t fuse\n",
      "the hoMe? sIher.'--\n",
      "fure of ar haild,\"--bried orvined mettidey worce,--Her, chat ofend deen had icure have if ind \n",
      "----\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration 68000, loss: 52.225743\n",
      "----\n",
      " \n",
      "powat\n",
      "eesingtes she haf mead, thot to ourtin she in he sufwenting to paing so maklous with, reche do prod has che tulatest notigh not ary to the tuccumesing.\n",
      "Shing--brlegined hare.\"\n",
      "\n",
      "\"at coreratt of  \n",
      "----\n",
      "iteration 69000, loss: 51.697257\n",
      "----\n",
      " enst mond the mas was sumtseng.\n",
      "Torionsed;\n",
      "and the thigd she of wim ro.--Wed genelerigheng.\n",
      "Wesurt bot. vere Food invernound stee, you tivey.--Mrs madat ar he mo hous,\n",
      "have as shigh.\n",
      "Bor her-dent; ong \n",
      "----\n",
      "iteration 70000, loss: 50.923837\n",
      "----\n",
      " ne whit wald and bet; at utlen onjorcere sent of as, her. Mrdan pleate to crastore rom do Ement this\n",
      "indet Mld ufating!--\n",
      "ithbuve, ble; whel mustry\n",
      "of ippe le it oth bir,\n",
      "whon weppeentll a Ttas he tma \n",
      "----\n",
      "iteration 71000, loss: 50.734812\n",
      "----\n",
      "  son Whive raying beed,\n",
      "_poos to mo, hise be fare har ar, of had we they teming even pmvery porcoubt from mus. Emma, in moghen thiplele's pistorints wess ather to larpicill matl's bne\n",
      "a  I the ealedy, \n",
      "----\n",
      "iteration 72000, loss: 50.599726\n",
      "----\n",
      "  oolite wos fief in ledion Ha heven arntap\n",
      "anot hes it sompe till to fush comle from way and, twit gobllun ofe nobjuch of.  He henhesed that bpean was \"uncorned nigy she inday mive use, mare fangit ol \n",
      "----\n",
      "iteration 73000, loss: 50.533135\n",
      "----\n",
      " it to it.\n",
      "\n",
      "Thacwid in I\n",
      "heans: cone whou_ dous shate mowt whade in onm therrithe.\n",
      "I byice ro \"ould whelrar\n",
      "uflfitudaen Mes ower;\n",
      "\"I tere bestlanking the beiniges.\n",
      "\n",
      "\n",
      "Emal andiss in camy be fake of no m \n",
      "----\n",
      "iteration 74000, loss: 50.152489\n",
      "----\n",
      " d amy er beterst hads\n",
      "thiqk,\n",
      "who do here ankere\n",
      "the fill, very, and whack amy ofe deet habut she was minor of qunsment.\n",
      "\n",
      "Hathup yfure what bes; \"hers pifteard thep, luitak bow\n",
      "frot ly hopof in wagit o \n",
      "----\n",
      "iteration 75000, loss: 49.829404\n",
      "----\n",
      " ent,\n",
      "at Mr.\"\n",
      "ot Mrt evere itte of sconde,\n",
      "Himpatted nore tood thall ale of werped,\" she\n",
      "to I dor  Nonred, the his she chitiduin notheld a mepliollet soneaysle a the ink so che.  Ha  \"Is you Hise Mrtor \n",
      "----\n",
      "iteration 76000, loss: 49.866524\n",
      "----\n",
      " to may by.\n",
      "\n",
      "Shackes and wet wo wruce, thit nowe.\"\n",
      " as or fred rear and pure oallegient the of pery of the mlooth he she xardss Emme mapingalst mery\n",
      "\n",
      "\n",
      "\n",
      "\"Iyens to it conon owa.  nown en to dafrining wil \n",
      "----\n",
      "iteration 77000, loss: 50.072323\n",
      "----\n",
      " s carery, could the her not  Mar.\n",
      "\n",
      "\n",
      "Y;\n",
      "\n",
      "Harrien's if sucwing frot to of pacteseas thmeatessaged the bited lost ad a compe merse go menn\n",
      "to dosst reing\n",
      "ald I pliguntay\n",
      "Emmare, py rall Harn, dehit. Knis \n",
      "----\n",
      "iteration 78000, loss: 49.840136\n",
      "----\n",
      "  as tillistous\n",
      "I houss\n",
      "Falk hit have hak Mardele\n",
      "ath to tomesers go reverdtht fert hothill, Hans--thaes, have ofayting somplat--ve\n",
      "out be oad and. Elialy\n",
      "the dethoug mabiel sayce haar hather to lly yo \n",
      "----\n",
      "iteration 79000, loss: 49.684119\n",
      "----\n",
      " ot to Emleady dos im-kingtorchult.\n",
      "\n",
      "\"Mith.  Suld asoot theiioust youce ifn the. .\n",
      "\n",
      "\"Misnoud had sush of Peardavel, path Wourd! the be coule mounes; mimen suy imffin, has; ind him ferave and\n",
      "ad witaden \n",
      "----\n",
      "iteration 80000, loss: 49.160721\n",
      "----\n",
      " sthizer her to her\n",
      "of rear seoursed\n",
      "of applefinterpbate suthonluritlor the so ondor cond ppise nad he she thew who thact been of buk!\n",
      "sy!\n",
      "\n",
      "Mrstion my wastling, masct fand Mrte froyhelle the it jualabl \n",
      "----\n",
      "iteration 81000, loss: 48.940431\n",
      "----\n",
      " ee dar he jy\n",
      "mont,\n",
      "wer fig anost tisey sett Mas. El she ert\n",
      "one che wou'd, a dusesure arnice an no was otht obet thams_ fhat terong nottelss so sta.. Mrtueth as forally gimt we biviging; of a fors. He \n",
      "----\n",
      "iteration 82000, loss: 48.586482\n",
      "----\n",
      " nnentube his to desieg lassing thate forforatilul ffriius in shepras amrecher mizy wast's of to fored.\n",
      "I thas, unetwot adge, mitt dould Emmasson weshor. Kning me with bookeghd aed\n",
      "twate Mrting own onc \n",
      "----\n",
      "iteration 83000, loss: 49.028697\n",
      "----\n",
      "  as plalan for vurink as of the that and\n",
      "allstow nebey assbice to hard sornowes.--\n",
      "Yod every camaly to ousoll tho in masthed,\n",
      "andy thay aed: spequy exwour,\n",
      "forsed her modes\n",
      "way _verable Heverress was  \n",
      "----\n",
      "iteration 84000, loss: 48.996513\n",
      "----\n",
      " e be athf, amemensed acasicuself whes,\n",
      "\"I wild nectoustboid\n",
      "a spon may had of hos whow sentend.\"\n",
      "\n",
      "I ustos, and and I of the lich she yored to beevinise.\n",
      "som nevercide nond--the reshey yout the mispiel \n",
      "----\n",
      "iteration 85000, loss: 48.958829\n",
      "----\n",
      "  doyingongy soad to the chet farma in every the sum othic, onfict as ove she besonates.\n",
      "To fines, anr had fiin,\n",
      "kester thatle damy than in the dire he sucheanding me his wascighing butquary ond cone,  \n",
      "----\n",
      "iteration 86000, loss: 48.619984\n",
      "----\n",
      " utmoslady,\n",
      "to withent\n",
      "of not has geay, Himear she Harnce Miss Mrsurevery comentake\n",
      "tome nepextilidiaad besite, wors walcttamt what bo've pabed dt they of pompat by and her.--spontes-will only deal\n",
      "fat \n",
      "----\n",
      "iteration 87000, loss: 48.551334\n",
      "----\n",
      " oteld wisowant leaid was  I never of incor beer or moons; it\n",
      "frou of sermave frage thaigh plen she themmett Foidholl hou neould you a go, she mad they so mund.\n",
      "\n",
      "\"Nract:e is nod.\"\n",
      "\n",
      "\"Punkess he very ase \n",
      "----\n",
      "iteration 88000, loss: 48.399615\n",
      "----\n",
      "  go ard\n",
      "so patceld phe the a quill out of yot dam, dald was her.--Thise, were, ners fitling the. Not nosas but it lorcay a sbec, such tere greaych nowh, do I of Mrwrre Mes hinf so come Mr. Knig the da \n",
      "----\n",
      "iteration 89000, loss: 48.408855\n",
      "----\n",
      "  forg them tompent is certlen, Jhe of a mely.\"\n",
      "Masse\n",
      "the he mare to not the deast\n",
      "by le -\"Pere beided nould sack,,\n",
      "was prmel efce seche bnayfers, ad anwising could lire been meve.  Shape pere, and ofr \n",
      "----\n",
      "iteration 90000, loss: 48.459011\n",
      "----\n",
      " Mr. Wephiseny haver to loly, herst bestle Faighllent.\n",
      "\n",
      "\"You.  and ad I itblien feangesied\n",
      "he gon lot it been not doall\n",
      "her fromentend ach mual co macibte Mr.  I lathigasp, the tist now and necirnes se \n",
      "----\n",
      "iteration 91000, loss: 48.664915\n",
      "----\n",
      " ech saidh suhined ath arap to bus am sadeat loy a klon mlaat onerec_ were all anl forrinfenbakey I have dich she she.\n",
      "\n",
      "Ath whor, tham Emmabust.  Waal,\n",
      "but entall, So ferpieg chen confore hand mursely, \n",
      "----\n",
      "iteration 92000, loss: 48.301001\n",
      "----\n",
      " y, Fairinwbugoun mo staty think mod theakar alw dreaw walwellss wers marins, if otherd ald Emme saisthonle som her it Emmains cit vers\n",
      "the ifting.\n",
      "A in fary her have and vise beslan age on the obsedly \n",
      "----\n",
      "iteration 93000, loss: 48.410204\n",
      "----\n",
      " a. I\n",
      "dives, all to gooling werpaled weaw aly fers abg,\n",
      "shis the\n",
      "was caming mpits,\" Jank you or thal\n",
      "tool of _noilfiet, and will no had, a\n",
      "deed erd exsurter Might erest.  Yojintule a be timt frat ar to \n",
      "----\n",
      "iteration 94000, loss: 47.939238\n",
      "----\n",
      " the\n",
      "sne dasticy!-\n",
      "\n",
      "Wect ofwoun a wing thank.\"\n",
      "\n",
      "\n",
      "Yow vear thareing not\n",
      "so so mmed not ap Mr abet,\n",
      "youccully his whiteve\n",
      "was so felibned that the beesing bever as my a tatlen ifforicces\n",
      "her was butalf t \n",
      "----\n",
      "iteration 95000, loss: 48.062812\n",
      "----\n",
      " he so dixtall one plead wemmed Emmants ixourted's, inttied thaw cumnodh walkend beall be thiche the a by mave godad conder redtean.\n",
      "\n",
      "\"He restelfenly the mo sermected, whack plen bued it onore her\n",
      "dell \n",
      "----\n",
      "iteration 96000, loss: 48.177252\n",
      "----\n",
      " inche;\n",
      "onding, and ad houfd.  She datiealmsturllying of pill; ap whound!\n",
      "by, aprare mes. Knes owet very somabeadite, Fret on ut. Kno cayeer wous!\"\n",
      "\n",
      "\"Noome, neck astlotlood-pod in ofse his-priet I disc \n",
      "----\n",
      "iteration 97000, loss: 48.473815\n",
      "----\n",
      " at or that youettelfend's darite\n",
      "ally to gikence;\n",
      "of to ver, abliriag outhing--wall have, bued _Mill exchd!--jornoupped up\n",
      "beit a what me sey such and hers she fore, and in a spow he dessing poretred. \n",
      "----\n",
      "iteration 98000, loss: 48.502825\n",
      "----\n",
      "  have beer apport!--\n",
      "Mr.. Famed had-ptam in him, an. with gaideren spirstyon foeve, wiresontle.  Whakes,\n",
      "loo's's orused the depiinon siry ay done bighaeghentoble her and gange Emman in wathor my of al \n",
      "----\n",
      "iteration 99000, loss: 47.897887\n",
      "----\n",
      " ion, Botiriting to bust howirl which sepperth be)t\"ston, sake equal waid thould I dave Harrat thay wad uncone or Emmoosforing ton mpising pidtand lother en, acwery\n",
      "with I a k\"_ Cough; \"I wall now.\n",
      "\n",
      "\"B \n",
      "----\n",
      "iteration 100000, loss: 47.810170\n",
      "----\n",
      " ee in could el comle lo wte; bleame have happots! ifsice.  mirn with sause not's cased haugh to have,\n",
      "laginvak push\" Ust me to ancesotadent, and merarlos wo?  \"dod!--\n",
      "She may that one sthave this fang \n",
      "----\n"
     ]
    }
   ],
   "source": [
    "n, p = 0, 0\n",
    "mwxh, mwhh, mwhy = np.zeros_like(wxh), np.zeros_like(whh), np.zeros_like(why)\n",
    "mbh, mby = np.zeros_like(bh), np.zeros_like(by) #mem variables for Adagrad\n",
    "\n",
    "smooth_loss = -np.log(1.0/len(unique_chars))*seq_length #loss at iteration 0\n",
    "\n",
    "while n<= 100e3:\n",
    "    #prep inputs \n",
    "    if p+seq_length+1 >= len(data) or n==0:\n",
    "        hprev = np.zeros((hidden_size,1)) #reset RNN mem\n",
    "        \n",
    "        p = 0\n",
    "        \n",
    "    inputs = [char_to_idx[ch] for ch in non_unique[p:p+seq_length]]\n",
    "    targets = [char_to_idx[ch] for ch in non_unique[p+1:p+seq_length+1]]\n",
    "    \n",
    "    #forward chars through net and fetch grad\n",
    "    \n",
    "    loss, dwxh, dwhh, dwhy, dbh, dby, hprev = lossfun(inputs, targets, hprev)\n",
    "    smooth_loss = smooth_loss * 0.999 + loss * 0.001\n",
    "    \n",
    "    # sample from model every 1000 iterations\n",
    "    \n",
    "    if n % 1000 == 0:\n",
    "        print(\"iteration %d, loss: %f\" % (n, smooth_loss))\n",
    "        sample(hprev, inputs[0], 200)\n",
    "        \n",
    "    #perform param update with adagrad\n",
    "        \n",
    "    for param, dparam, mem in zip([wxh, whh, why, bh, by],\n",
    "                                 [dwxh, dwhh, dwhy, dbh, dby],\n",
    "                                 [mwxh, mwhh, mwhy, mbh, mby]):\n",
    "        mem += dparam * dparam\n",
    "        param += -learning_rate * dparam/ np.sqrt(mem + 1e-8) #adagrad update\n",
    "        \n",
    "    p += seq_length\n",
    "    n += 1\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----\n",
      " tiring on to tremary, vear_ shall it.\n",
      "Che reay her home your?--sherite his have what deedstent pher\n",
      "che dounnersed disikime hous arsore macricurtat to the to was the Rant in ald falks; dalf\n",
      "her tid. W \n",
      "----\n"
     ]
    }
   ],
   "source": [
    "sample(hprev, char_to_idx['a'], 200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
